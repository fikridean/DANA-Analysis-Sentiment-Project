{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "YOc6TQ8sJwpH",
        "outputId": "20013664-5cb9-4440-c0d7-b24532254044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: I love this app! \n",
            "Predicted: positive\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "load_model = joblib.load('svm_model.pkl')\n",
        "load_tfidf = joblib.load('svm_tfidf.pkl')\n",
        "\n",
        "label_map = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
        "\n",
        "def predict_sentiment(input):\n",
        "    vectorized = load_tfidf.transform([input])\n",
        "    prediction = load_model.predict(vectorized.toarray())\n",
        "    predicted_label = label_map[prediction[0]]\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "input = \"I love this app!\"\n",
        "predicted = predict_sentiment(input)\n",
        "print(f\"Input: {input} \\nPredicted: {predicted}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AUv9ZfloJwpI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: I love this app! \n",
            "Predicted: positive\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "load_model = joblib.load('rf_model.pkl')\n",
        "load_tfidf = joblib.load('rf_tfidf.pkl')\n",
        "\n",
        "label_map = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
        "\n",
        "def predict_sentiment(input):\n",
        "    vectorized = load_tfidf.transform([input])\n",
        "    prediction = load_model.predict(vectorized.toarray())\n",
        "    predicted_label = label_map[prediction[0]]\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "input = \"I love this app!\"\n",
        "predicted = predict_sentiment(input)\n",
        "print(f\"Input: {input} \\nPredicted: {predicted}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "qjZxXuZyJwpI",
        "outputId": "f51b8952-2e79-450a-cce8-006031d0312e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: I love this app! \n",
            "Predicted: positive\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "load_model = joblib.load('gbm_model.pkl')\n",
        "load_tfidf = joblib.load('gb_tfidf.pkl')\n",
        "\n",
        "label_map = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
        "\n",
        "def predict_sentiment(input):\n",
        "    vectorized = load_tfidf.transform([input])\n",
        "    prediction = load_model.predict(vectorized.toarray())\n",
        "    predicted_label = label_map[prediction[0]]\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "input = \"I love this app!\"\n",
        "predicted = predict_sentiment(input)\n",
        "print(f\"Input: {input} \\nPredicted: {predicted}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmH4S7l_JwpJ",
        "outputId": "c0524a20-c111-4ff9-87bd-82634844aeb5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79cf8c9cacb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step\n",
            "Input: I love this app! \n",
            "Predicted: positive\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import json\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "load_model = load_model('lstm_model.h5')\n",
        "with open('lstm_tokenizer.json') as f:\n",
        "    tokenizer_json = json.load(f)\n",
        "lstm_tokenizer = tokenizer_from_json(tokenizer_json)\n",
        "\n",
        "label_mapping = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
        "\n",
        "def predict_sentiment(input):\n",
        "    sequence = lstm_tokenizer.texts_to_sequences([input])\n",
        "    padded = pad_sequences(sequence)\n",
        "\n",
        "    predict = load_model.predict(padded)\n",
        "\n",
        "    predicted_label_index = predict.argmax(axis=-1)[0]\n",
        "    predicted_label = label_mapping[predicted_label_index]\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "input = \"I love this app!\"\n",
        "predicted = predict_sentiment(input)\n",
        "print(f\"Input: {input} \\nPredicted: {predicted}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
